\textbf{Abstract:} Fault prediction models are becoming incresingly more popular by companies that wish to decrease the amount of errors in their system and the work of the developers in finding these errors. Many different prediction models have been introdced and tested in many difference scientific experiments. In our project we have tested Decision trees against Bayesian learners in order to see if there is a difference in prediction quality. We have also looked into the number of metrics used for a prediction model, and if increasing the number of metrics, also increases the performance of the prediction model. For the prediction model we used metrics like Lines of Code, Cyclomatic complexity and number of unique operands. We used the evaluation metrics \% correctness, F-measure and AUC to evaluate our results. In order to learn how the models performed in general we did t-testing on the data and learned that decision trees seem to perform better than bayesian learners, however not by a big percentage. \\ We also wanted to look into the number of metrics and if the number affected the performance of the prediction model. However, the outcome of our experiment did not show any precise pattern in performance and therefore we cannot say that the number of metrics make a difference in how precise the performance model is. However is should also be mentioned that this experiment was in a small scale, and in order to complety rule out that the number of metrics have an influence on how precise the prediction model is, a number of larger experiments should be created. 