\textbf{Abstract:} Fault prediction models are becoming increasingly more popular by companies that wish to decrease the amount of errors in their system and the work of the developers in finding these errors. Many different prediction models have been introduced and tested in many difference scientific experiments. In our project we have tested Decision trees against Bayesian learners in order to see if there is a difference in prediction quality. We have also looked into the number of metrics used for a prediction model, and if increasing the number of metrics, also increases the performance of the prediction model. For the prediction model we used metrics like Lines of Code, cyclomatic complexity and number of unique operands. We used   Correctness, F-measure and AUC to evaluate our results. In order to verify the results we did t-testing on the experiment output data and learned that decision trees seem to perform better than Bayesian learners, however not by a big percentage. \\ We also inspected how the number of metrics affects the performance of the prediction model. However, the outcome of our experiment did not show any precise pattern in performance and therefore we cannot say that the number of metrics make a difference in how precise the performance model is. However to complety rule out the option that number of metrics have an influence on how precise the prediction model is, a larger experiment should be executed (especially since we have also found articles which claim the opposite). 