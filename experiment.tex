Since we want to gain from our experiment as much knowledge from SFP field as possible, we've decided to carry out rather simple tests of several decision tree and bayesian algorithms to see how they perform on NASA MDP data sets. We carried tests with the whole datasets as well as with data sets restricted just on chosen code metrics. To deal with the lack of data but still avoid overfitting, we're mostly using K-fold cross validation approach. Here is needed to mention, that in WEKA, K-fold validation is executed internally to estimate the generalization error and the output model is the model trained on the whole dataset (partial K-fold models are not shown to the user). We utilize this to also perform our own tests with the datasets where this is possible (due to their sufficient size).

\subsection{Evaluation metrics}
To compare models(classifiers) and evaluate their performance, there are several metrics which can be used. To decide which to use, we have again taken look into Malhotra's article\cite{malhotra2015systematic} to find out that the most used ones are usually recall, precision, area under the curve(AUC) and F-measure. WEKA outputs all of these so we utilized it to compare trained classifiers with several of these metrics.