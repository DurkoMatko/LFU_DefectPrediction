\subsection{Decision Trees}
To compare the decision trees performance, we used the CM1 NASA dataset

CM1 is a spacecraft instrument used for data collection and processing written in C. We obtained from PROMISE repository and it contains 38 metrics including static code metrics like McCabe or Halstead metrics.

After cross-validating 7 different decision trees, we obtained the results which can be seen in table \ref{table:DT_allMetrics_CM1}.

\definecolor{myRed}{RGB}{219, 48, 122}

\begin{table}[h!]
\centering
\begin{tabular}{ |c|c|c|c|c|c| } 
 \hline
 \textbf{Algorithm} & \textbf{Correct [\%]} & \textbf{Recall} & \textbf{Precision} & \textbf{F-Measure} & \textbf{AUC}  \\ 
 \hline
 Decision Stump & \textcolor{myRed}{87.156} & \textcolor{myRed}{.872} & .760 & .812 & .713   \\ 
 \hline
 HoeffDing Tree & \textcolor{myRed}{87.156} & \textcolor{myRed}{.872} & .760 & .812 & .477   \\ 
 \hline
  J48 & 83.792 & .838 & \textcolor{myRed}{.822} & \textcolor{myRed}{.829} & .622   \\ 
 \hline
  LMT & 86.8502 & .869 & .815 & .821 & .714    \\ 
 \hline
  Random Forest & 85.6269 & .856 & .790 & .814 & \textcolor{myRed}{.770}   \\ 
 \hline
  Random Tree & 79.5107 & .795 & .813 & .803 & .588   \\ 
 \hline
 REP tree  & 86.8502 & .869 & .759 & .810 & .554   \\ 
 \hline
\end{tabular}
\caption{Decision trees performance using all code metrics of CM1 dataset}
\label{table:DT_allMetrics_CM1}
\end{table}


At this point, we've restricted the dataset only on chosen metrics and observed the changes  in classifiers' performance.

Results for chosen code metric - McCabe's cyclomatic complexity / Lines of code (LOC) can be seen in tables \ref{table:DT_complexity_CM1} and \ref{table:DT_LOC_CM1} respectively.

\begin{table}[h!]
\centering
\begin{tabular}{ |c|c|c|c|c|c| } 
 \hline
 \textbf{Algorithm} & \textbf{Correct [\%]} &  \textbf{Recall} & \textbf{Precision} & \textbf{F-Measure} & \textbf{AUC}  \\ 
 \hline
 Decision Stump & \textcolor{myRed}{87.156} & \textcolor{myRed}{.872} & .760 & .812 & .513    \\ 
 \hline
 HoeffDing Tree & 86.8502 & .869 & \textcolor{myRed}{.804} & \textcolor{myRed}{.816} & .490   \\ 
 \hline
  J48 & \textcolor{myRed}{87.156} & \textcolor{myRed}{.872} & .760 & .812 & .480\\ 
 \hline
  LMT & 86.8502 & .869 & .759 & .810 & \textcolor{myRed}{.601}  \\ 
 \hline
  Random Forest & 85.0153 & .850 & .793 & .814 & .471 \\ 
 \hline
  Random Tree & 84.4037 & .844 & .788 & .811 & .486 \\ 
 \hline
 REP tree  & \textcolor{myRed}{87.156} & \textcolor{myRed}{.872} & .760 & .812 & .477 \\ 
 \hline
\end{tabular}
\caption{Decision trees performance using only cyclomatic complexity of CM1 dataset}
\label{table:DT_complexity_CM1}
\end{table}


\begin{table}[h!]
\centering
\begin{tabular}{ |c|c|c|c|c|c| } 
 \hline
 \textbf{Algorithm} & \textbf{Correct [\%]} &  \textbf{Recall} & \textbf{Precision} & \textbf{F-Measure} & \textbf{AUC}  \\ 
 \hline
 Decision Stump & \textcolor{myRed}{87.156}& \textcolor{myRed}{.872} & .760 & .812 & .647    \\ 
 \hline
 HoeffDing Tree & 86.5443 & .865 & .759 & .809 & .483   \\ 
 \hline
  J48 & \textcolor{myRed}{87.156} & \textcolor{myRed}{.872} & .760 & \textcolor{myRed}{.812} & .477\\ 
 \hline
  LMT & 86.5443 & .865 & .759 & .809 & \textcolor{myRed}{.669}  \\ 
 \hline
  Random Forest & 81.6514 & .817 & \textcolor{myRed}{.787} & .800 & .571 \\ 
 \hline
  Random Tree & 78.2875 & .783 & .785 & .784 & .527 \\ 
 \hline
 REP tree  & \textcolor{myRed}{87.156} & \textcolor{myRed}{.872} & .760 & .812 & .477 \\ 
 \hline

\end{tabular}
\caption{Decision trees performance using only LOC of CM1 dataset}
\label{table:DT_LOC_CM1}
\end{table}

To check if some potential patterns found in results will be observed again we performed exactly same tests with the JM1 dataset as well. Results can be seen in table \ref{table:DT_allMetrics_JM1},table \ref{table:DT_complexity_JM1} and table \ref{table:DT_LOC_JM1}.

\begin{table}[h!]
\centering
\begin{tabular}{ |c|c|c|c|c|c| } 
 \hline
 \textbf{Algorithm} & \textbf{Correct [\%]} & \textbf{Recall} & \textbf{Precision} & \textbf{F-Measure} & \textbf{AUC}  \\ 
 \hline
 Decision Stump & 81.6637 & .817 & .667 & .734 & .641   \\ 
 \hline
 HoeffDing Tree & 81.4761 & .815 & .760 & .764 & .565   \\ 
 \hline
  J48 & 79.9333 & .799 & .767 & .777 & .649   \\ 
 \hline
  LMT & 82.0077 & .820 & .779 & .762 & .704    \\ 
 \hline
  Random Forest & \textcolor{myRed}{82.6644} & \textcolor{myRed}{.827} & \textcolor{myRed}{.796} & \textcolor{myRed}{.796} & \textcolor{myRed}{.760}   \\ 
 \hline
  Random Tree & 76.0555 & .761 & .762 & .761 & .591   \\ 
 \hline
 REP tree  & 81.4344 & .814 & .771 & .774 & .692   \\ 
 \hline
\end{tabular}
\caption{Decision trees performance using all code metrics of JM1 dataset}
\label{table:DT_allMetrics_JM1}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{ |c|c|c|c|c|c| } 
 \hline
 \textbf{Algorithm} & \textbf{Correct [\%]} & \textbf{Recall} & \textbf{Precision} & \textbf{F-Measure} & \textbf{AUC}  \\ 
 \hline
 Decision Stump & 81.6637 & .817 & .667 & .734 & \textcolor{myRed}{.699}   \\ 
 \hline
 HoeffDing Tree & 81.6533 & .817 & .764 & .752 & .660   \\ 
 \hline
  J48 & \textcolor{myRed}{81.9869} & \textcolor{myRed}{.820} & \textcolor{myRed}{.824} & .743 & .604   \\ 
 \hline
  LMT & 81.9243 & .819 & .804 & .743 & .660    \\ 
 \hline
  Random Forest & 81.7263 & .817 & .767 & .752 & .654   \\ 
 \hline
 Random Tree  & 81.6324 & .816 & .763 & \textcolor{myRed}{.753} & .647   \\ 
 \hline
 REP tree & 81.7992 & .818 & .775 & .745 & .609   \\ 
 \hline
\end{tabular}
\caption{Decision trees performance using only cyclomatic complexity of JM1 dataset}
\label{table:DT_complexity_JM1}
\end{table}


\begin{table}[h!]
\centering
\begin{tabular}{ |c|c|c|c|c|c| } 
 \hline
 \textbf{Algorithm} & \textbf{Correct [\%]} & \textbf{Recall} & \textbf{Precision} & \textbf{F-Measure} & \textbf{AUC}  \\ 
 \hline
 Decision Stump & 81.6637 & .817 & .667 & .734 & .643   \\ 
 \hline
 HoeffDing Tree & 80.9027 & .809 & .747 & .754 & \textcolor{myRed}{.698}   \\ 
 \hline
  J48 & \textcolor{myRed}{81.9347} & \textcolor{myRed}{.819} & \textcolor{myRed}{.790} & .747 & .655   \\ 
 \hline
  LMT & 81.8305 & .818 & .775 & .748 & .683    \\ 
 \hline
  Random Forest & 81.4865 & .815 & .765 & .763 & .681   \\ 
 \hline
 Random Tree  & 81.3927 & .814 & .765 & \textcolor{myRed}{.766} & .665   \\ 
 \hline
 REP tree & 81.6533 & .817 & .767 & .761 & .658   \\ 
 \hline
\end{tabular}
\caption{Decision trees performance using only LOC of JM1 dataset}
\label{table:DT_LOC_JM1}
\end{table}

As we can see from the results, all decision tree classifiers perform very similar. With smaller CM1 dataset, Decision Stump performed best with whole dataset as well as with only restricted metrics. J48 and REP joined Decision Stump in tests with restricted metrics. With  much bigger JM1 dataset, Random Forest performed best in casre all metrics were available. If we restricted dataset only on cyclomatic complexity or LOC, J48 had a slight edge. But as already stated before, the differences in results are very small. That's why we decided to perform same test on Bayesian classifiers and compare the results of these 2 groups.